---
title: "Replication of Inferring Whether Officials Are Corruptible From Looking at Their Faces by Lin, Adolphs & Alvarez (2018, Psychological Science)"
author: "Rondeline Williams (rondeline.williams@stanford.edu)"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  html_document:
    toc: yes
    toc_depth: 3
    toc_float:
      collapsed: false
---

##Introduction

The current study seeks to replicate findings from "Replication of Inferring Whether Officials Are Corruptible From Looking at Their Faces." I chose to replicate this study because it is outside my area of study (social psychology), but not my field (psychology). I currently study children's language development as a function of environmental factors such as auditory noise and have never had the opportunity to study adult behavior. In experiment 1 of this study, the researchers explored how adults used photos of unfamiliar state and federal officials to determine an official's level of agression, deception, and corruptibility. Results indicated that state and federal officials who were convicted of political corruption were viewed as more dishonest asnd deceptive than their peers with clean records.
The most challenging part of completing this replication study will be creating the set of photos/Likert scales to be uploaded to Mechanical Turk. Fortunately, the authors have provided additional information regarding their methods on OSF.

##Methods

###Participants
In line with the original paper, this study included 100 participants from Amazon Mechanical Turk (MTurk). Participants were 18 years of age or older, native English speakers, and located in the United States. Additionally, they completed high school or more and had normal or corrected-to-normal vision. All participants obtained a human intelligence task (HIT) approval rate of at least 95% and successfully completed 1000 or more assignments on MTurk. 

###Power Analysis

Original effect size, power analysis for samples to achieve 80%, 90%, 95% power to detect that effect size.  Considerations of feasibility for selecting planned sample size.

###Planned Sample

Planned sample size and/or termination rule, sampling frame, known demographics if any, preselection rules if any.

###Materials

All materials were collected in line with Lin et al. (2018) as follows. "Stimuli were photos of 72 real elected officials.All were Caucasian males who have held federal or state legislative offices in the United States. Photos were official headshots obtained from government websites and
personal campaign websites (63%), news articles (23%), and
Wikipedia (14%). All photos were converted to gray-scale 
Facial Inferences and Corruption 1809 images on a plain gray background and cropped to a uniform size. All faces were frontal, smiling, in clear focus, and centered in the middle of the image.
Among the 72 officials, half were convicted of
political corruption (corrupt officials), and the other
half had clean records (noncorrupt officials). The corrupt officials were from two Wikipedia data sets (list of
American state and local politicians convicted of crimes:
https://en.wikipedia.org/wiki/List_of_American_state_
and_local_politicians_convicted_of_crimes; list of
American federal politicians convicted of crimes:
https://en.wikipedia.org/wiki/List_of_American_fed
eral_politicians_convicted_of_crimes). To reduce
sources of variability, we included only officials who
were Caucasian, were male, held federal or state legislative offices, and were convicted between 2001 and 2016 of political corruption conducted while in office (bribery, money laundering, embezzlement, mail fraud, wire
fraud, tax fraud, conflict of interest, misusing funds,
misusing office, or falsifying records). In addition, age
information for these officials had to be publicly available, as did frontal photographs of acceptable clarity
in which the official was smiling. All photographs had
been taken while officials were in office. Most photos
of the corrupt officials had a known creation date, and
we confirmed that the photos were taken before their
conviction (72%); for the rest of the photos (28%), the
creation date was unknown (analyses were also performed when excluding data for these stimuli; the pattern of results did not change). The noncorrupt officials
were randomly matched from the list of incumbents
who had clean records, were holding the same office
in the same state, and were of the same gender, the
same race, and similar age (±12 years) as the corrupt
officials during the period of their misconduct. For
instance, if the stimuli contained a Caucasian male corrupt official who was a member of the Arizona House
of Representatives during his misconduct at the age of
55, then a noncorrupt official would be randomly
selected from our available stimulus set from the list of
Arizona House of Representatives incumbents who had
a clean record and who was a Caucasian male between
the ages of 43 and 67."

###Procedure	

The current study followed the original paper precisely. "Participants were not informed of the purpose of the study or the sampling of the stimuli. In particular, they were not given any information about the percentage of politicians in our stimulus set who might
be corrupt in real life. They were told only that they
would view a series of politician photos and that they
should judge how corruptible, dishonest, selfish, trustworthy, and generous these politicians looked to them
(experiment instructions are available at https://osf.io/
k4mds/). Participants completed five blocks of experiments, with each block corresponding to judging one trait
for all faces. The ordering of the faces within each block
as well as the ordering of the blocks were randomized.
Each block started with an instruction screen that
specified the trait to be judged (e.g., corruptibility).
Participants were instructed to make their decisions as
quickly and precisely as possible. Six practice trials
familiarized participants with the task. Participants
viewed photos of officials one at a time in randomized
order and made judgments. Each trial began with a
fixation cross, followed by the photo (1 s) with a 5-point
Likert scale below it. Scales were anchored with bipolar
adjectives. Participants could make a decision
as soon as the photo appeared and within 4 s after the
photo disappeared. The orientation of the scale was
randomized across blocks, and scores were reversecoded as needed.
After completing all five blocks of ratings, participants were asked whether they had recognized any of
the officials and filled out a short survey questionnaire on demographic characteristics, political attitudes, and
personality."

###Analysis Plan

Can also quote directly, though it is less often spelled out effectively for an analysis strategy section.  The key is to report an analysis strategy that is as close to the original - data cleaning rules, data exclusion rules, covariates, etc. - as possible.  

**Clarify key analysis of interest here**  You can also pre-specify additional analyses you plan to do.

###Differences from Original Study

Explicitly describe known differences in sample, setting, procedure, and analysis plan from original study.  The goal, of course, is to minimize those differences, but differences will inevitably occur.  Also, note whether such differences are anticipated to make a difference based on claims in the original article or subsequent published research on the conditions for obtaining the effect.

### Methods Addendum (Post Data Collection)

You can comment this section out prior to final report with data collection.

#### Actual Sample
  Sample size, demographics, data exclusions based on rules spelled out in analysis plan

#### Differences from pre-data collection methods plan
  Any differences from what was described as the original plan, or “none”.


##Results


### Data preparation

Data preparation following the analysis plan.
	
```{r include=F}
###Data Preparation
#Here, I will prepare to import dataset from MTurk. The next sections further outline this plan

####Load Relevant Libraries and Functions
#library(tidyverse)
#library(dplyr)
#library(ggplot2) 
#library(rmcorr)
#library(lme4)
#library(car)
#library(lsr)

####Import data
#read.csv()

#### Data exclusion / filtering
#Exclude any participants missing trials using `filter(is.na(D_Rating)== FALSE)`, `filter(is.na(S_Rating)== FALSE)`, `filter(is.na(T_Rating)== FALSE)`, `filter(is.na(G_Rating)== FALSE)`,  `filter(is.na(C_Rating)== FALSE)`
#Exclude participants who are not native English speakers. Note: I'm not quite sure how to do this, but I know I want to filter out any rows where the column response is No `filter(Language)`
#Exclude trials in which participants responded in less than 100ms, a proxy for familiarity with the elected officials offline. This would be similar to line 141

#### Prepare data for analysis - create columns etc.
#Columns will include: Subject_ID, D_Rating, T_Rating, C_Rating, S_Rating, G_Rating, Language, Vision, Education 
```

### Confirmatory analysis

Calculate means of each trait using `mean` 
summarise(Mean_C= mean(C_Rating)), repeat for other 4 traits

Test whether similar trait "valences" are correlated with participant ratings of officials using repeated measures correlation `rmcorr` 

Next test intracorrelation coefficients (ICCs) to identify whether ratings across participants were relatively consistent. Note: I am currently learning how to run this in R. 

Run a t-test to test for differences between pairings using `t.test` 

Plot results using `ggplot2`

*Side-by-side graph with original graph is ideal here*

###Exploratory analyses

Any follow-up analyses desired (not required).  

## Discussion

### Summary of Replication Attempt

Open the discussion section with a paragraph summarizing the primary result from the confirmatory analysis and the assessment of whether it replicated, partially replicated, or failed to replicate the original result.  

### Commentary

Add open-ended commentary (if any) reflecting (a) insights from follow-up exploratory analysis, (b) assessment of the meaning of the replication (or not) - e.g., for a failure to replicate, are the differences between original and present study ones that definitely, plausibly, or are unlikely to have been moderators of the result, and (c) discussion of any objections or challenges raised by the current and original authors about the replication attempt.  None of these need to be long.
